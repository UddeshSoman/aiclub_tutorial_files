{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40pdmHEzocRi",
        "outputId": "a7605e75-0631-4ad6-ae26-8f1ff7ddd2fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewNoSHUCnRMb"
      },
      "outputs": [],
      "source": [
        "#Importing dependencies\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from tensorflow.keras.models import Sequential\n",
        "from numpy import array, argmax, random, take\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import RNN, SimpleRNN, LSTM,  Embedding, RepeatVector\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "#For plotting the matplotlib graphs in notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4QDHw5ynRMh"
      },
      "outputs": [],
      "source": [
        "Data_path=\"/content/drive/MyDrive/Datasets/3Gram_love_data.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_GS4VYinRMk",
        "outputId": "4c14986a-8156-40b3-9339-877734d6e423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of data (5351, 3)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "column_names = ['word1', 'word2', 'word3']\n",
        "\n",
        "input_3gram = pd.read_csv(Data_path, delimiter='\\t', names=column_names) #Importing csv file with column names\n",
        "print(\"shape of data\", input_3gram.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9-AZ8OhnRMm",
        "outputId": "d5dbd20a-bd15-4228-ccd8-c6ff513c4618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few sample records from data \n",
            "      word1 word2    word3\n",
            "1133  love    of      the\n",
            "4123  love    it     when\n",
            "3580  love    to      see\n",
            "1942  love   and  support\n",
            "2935  love    to      see\n",
            "3929  love    it     when\n",
            "3747  love    it     when\n",
            "4185  love    it     when\n",
            "392   hate    to      use\n",
            "287   hate    to     have\n"
          ]
        }
      ],
      "source": [
        "print(\"Few sample records from data \\n\", input_3gram.sample(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kJOx-F4nRMo",
        "outputId": "6ac7ef47-6c9e-42b1-fc34-245320c20cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Frequency of word1 values \n",
            " love      4327\n",
            "loved      416\n",
            "hate       400\n",
            "hated       80\n",
            "loves       72\n",
            "lovely      24\n",
            "loving      24\n",
            "hates        8\n",
            "Name: word1, dtype: int64\n",
            "\n",
            "Frequency of word2 values \n",
            " to         1866\n",
            "it         1361\n",
            "the         548\n",
            "with        240\n",
            "him         144\n",
            "you         144\n",
            "of          136\n",
            "her         104\n",
            "for          96\n",
            "and          88\n",
            "what         56\n",
            "is           48\n",
            "each         40\n",
            "in           40\n",
            "ones         32\n",
            "me           32\n",
            "nothing      32\n",
            "them         32\n",
            "as           24\n",
            "every        24\n",
            "more         16\n",
            "going        16\n",
            "that         16\n",
            "being        16\n",
            "affair       16\n",
            "my           16\n",
            "about         8\n",
            "your          8\n",
            "on            8\n",
            "letter        8\n",
            "most          8\n",
            "thy           8\n",
            "view          8\n",
            "song          8\n",
            "makes         8\n",
            "got           8\n",
            "this          8\n",
            "at            8\n",
            "a             8\n",
            "one           8\n",
            "hearing       8\n",
            "story         8\n",
            "all           8\n",
            "lost          8\n",
            "man           8\n",
            "when          8\n",
            "husband       8\n",
            "Name: word2, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFrequency of word1 values \\n\", input_3gram[\"word1\"].value_counts())\n",
        "print(\"\\nFrequency of word2 values \\n\", input_3gram[\"word2\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVUHCmC7nRMq",
        "outputId": "93a14cb5-6c6e-402c-d713-70eb2913298c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of unique words overall: 139\n",
            "unique words list: ['a' 'able' 'about' 'admit' 'affair' 'affection' 'all' 'and' 'another'\n",
            " 'answer' 'as' 'at' 'be' 'because' 'being' 'better' 'between' 'bother'\n",
            " 'break' 'care' 'cared' 'come' 'concern' 'country' 'cut' 'disappoint' 'do'\n",
            " 'each' 'every' 'fact' 'feel' 'feeling' 'find' 'first' 'for' 'from' 'get'\n",
            " 'go' 'god' 'going' 'got' 'hate' 'hated' 'hates' 'have' 'he' 'hear'\n",
            " 'hearing' 'her' 'here' 'him' 'his' 'husband' 'i' 'idea' 'if' 'in'\n",
            " 'interrupt' 'is' 'it' 'kind' 'know' 'leave' 'letter' 'life' 'like'\n",
            " 'listen' 'look' 'lost' 'lot' 'love' 'loved' 'lovely' 'loves' 'loving'\n",
            " 'make' 'makes' 'man' 'marriage' 'me' 'minute' 'more' 'most' 'much'\n",
            " 'music' 'my' 'nature' 'neighbor' 'not' 'nothing' 'of' 'on' 'one' 'ones'\n",
            " 'or' 'other' 'over' 'play' 'respect' 'say' 'see' 'sit' 'smell' 'so'\n",
            " 'someone' 'song' 'sound' 'story' 'stronger' 'support' 'take' 'talk'\n",
            " 'tell' 'than' 'that' 'the' 'them' 'they' 'think' 'this' 'thought' 'thy'\n",
            " 'to' 'too' 'united' 'use' 'very' 'view' 'watch' 'way' 'we' 'what' 'when'\n",
            " 'wife' 'will' 'with' 'work' 'you' 'your']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "unique_words = []\n",
        "for i in list(input_3gram.columns.values):\n",
        "    for j in pd.unique(input_3gram[i]):\n",
        "        unique_words.append(j)\n",
        "unique_words = np.unique(unique_words)\n",
        "\n",
        "\n",
        "print('Count of unique words overall:', len(unique_words))\n",
        "print('unique words list:', unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyOoGTT1nRMt"
      },
      "outputs": [],
      "source": [
        "word_indices = dict((w, i) for i, w in enumerate(unique_words))\n",
        "indices_words = dict((i, w) for i, w in enumerate(unique_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq0I6ZgjnRMx",
        "outputId": "0e0a2578-69d4-4444-96c1-e4a2f1ac3fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word1_onehot shape is  (5351, 139)\n"
          ]
        }
      ],
      "source": [
        "### Onehot encoding of word1\n",
        "word1 = input_3gram['word1'].map(word_indices)\n",
        "word1_onehot = keras.utils.to_categorical(np.array(word1), num_classes=len(word_indices))\n",
        "print(\"word1_onehot shape is \",word1_onehot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0deheDBanRM2",
        "outputId": "11e49836-8b6f-4e05-ca10-629fb1e1fa05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word2_onehot shape is  (5351, 139)\n",
            "word3_onehot shape is  (5351, 139)\n"
          ]
        }
      ],
      "source": [
        "##one hot encoding for word2 and word3 \n",
        "word2 = input_3gram['word2'].map(word_indices)\n",
        "word2_onehot = keras.utils.to_categorical(np.array(word2), num_classes=len(word_indices))\n",
        "print(\"word2_onehot shape is \",word2_onehot.shape)\n",
        "\n",
        "word3 = input_3gram['word3'].map(word_indices)\n",
        "word3_onehot = keras.utils.to_categorical(np.array(word3), num_classes=len(word_indices))\n",
        "print(\"word3_onehot shape is \",word3_onehot.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GOPfwHonRNH"
      },
      "source": [
        "## RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91l3EPz2nRNL"
      },
      "source": [
        "## Word prediction using RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCEYP4mknRNM",
        "outputId": "e9fd4c88-a57c-4833-d9b2-fd54f787f19f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word1_word2_onehot shape (5351, 2, 139)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "word1_word2 = input_3gram[['word1','word2']]\n",
        "for i in list(word1_word2.columns.values):\n",
        "    word1_word2[i] = word1_word2[i].map(word_indices)\n",
        "\n",
        "word1_word2=np.array(word1_word2)\n",
        "#The same data is reshaped with similar structure but appended with 1 value to make it 3d array\n",
        "word1_word2=np.reshape(word1_word2,(word1_word2.shape[0],2,1))\n",
        "word1_word2_onehot = keras.utils.to_categorical(np.array(word1_word2), num_classes=len(word_indices))\n",
        "print(\"word1_word2_onehot shape\", word1_word2_onehot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYWvBAD5nRNM",
        "outputId": "84e61c1f-0ac0-4f2a-869a-e0a002b119da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time steps 2\n",
            "Input nodes 139\n",
            "output nodes 139\n"
          ]
        }
      ],
      "source": [
        "print(\"time steps\" , word1_word2_onehot.shape[1])\n",
        "print(\"Input nodes\" , word1_word2_onehot.shape[2])\n",
        "print(\"output nodes\" , word3_onehot.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBMd_ZY8nRNN",
        "outputId": "8c28f076-8f1d-4d07-b2a2-417e250f8905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 30)                5100      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 139)               4309      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,409\n",
            "Trainable params: 9,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_rnn = Sequential()\n",
        "#model.add(SimpleRNN('number of hidden nodes in each rnn cell', input_shape=(timesteps, input_data_dim)))\n",
        "model_rnn.add(SimpleRNN(30, input_shape=(word1_word2_onehot.shape[1],word1_word2_onehot.shape[2]))) \n",
        "model_rnn.add(Dense(word3_onehot.shape[1], activation='softmax'))\n",
        "model_rnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRJuUw6WnRNO",
        "outputId": "4f068e5e-2172-4f56-9403-79dda0ccc1a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "168/168 [==============================] - 3s 4ms/step - loss: 3.7305 - accuracy: 0.3898\n",
            "Epoch 2/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 2.7377 - accuracy: 0.4971\n",
            "Epoch 3/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 2.3265 - accuracy: 0.5317\n",
            "Epoch 4/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 2.0590 - accuracy: 0.5726\n",
            "Epoch 5/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.8739 - accuracy: 0.5855\n",
            "Epoch 6/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.7350 - accuracy: 0.6064\n",
            "Epoch 7/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.6272 - accuracy: 0.6247\n",
            "Epoch 8/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.5374 - accuracy: 0.6365\n",
            "Epoch 9/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.4648 - accuracy: 0.6485\n",
            "Epoch 10/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.4055 - accuracy: 0.6571\n",
            "Epoch 11/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.3565 - accuracy: 0.6599\n",
            "Epoch 12/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.3181 - accuracy: 0.6636\n",
            "Epoch 13/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.2872 - accuracy: 0.6617\n",
            "Epoch 14/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.2628 - accuracy: 0.6606\n",
            "Epoch 15/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.2432 - accuracy: 0.6653\n",
            "Epoch 16/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.2287 - accuracy: 0.6638\n",
            "Epoch 17/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.2160 - accuracy: 0.6649\n",
            "Epoch 18/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.2065 - accuracy: 0.6636\n",
            "Epoch 19/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.1981 - accuracy: 0.6659\n",
            "Epoch 20/20\n",
            "168/168 [==============================] - 1s 4ms/step - loss: 1.1914 - accuracy: 0.6632\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa4c03ed250>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# compile network\n",
        "model_rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "model_rnn.fit(word1_word2_onehot, word3_onehot, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdBysw11nRNP"
      },
      "outputs": [],
      "source": [
        "def rnn_word_pred(in_text):\n",
        "    print(\"Input is - \" , in_text, end = ' ')\n",
        "    encoded = [word_indices[i] for i in in_text]\n",
        "    encoded = np.array(encoded).reshape(1,2,1)\n",
        "    encoded =keras.utils.to_categorical(np.array(encoded), num_classes=len(word_indices))\n",
        "    #ypred = model_rnn.predict_classes(encoded, verbose=0)[0]\n",
        "    predict_(x=model_rnn.predictencoded) \n",
        "    classes_x=np.argmax(predict_x, axis=1)\n",
        "   # print(classes_x)\n",
        "    print(indices_words[classes_x[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7GftvASnRNQ",
        "outputId": "b1e9faeb-011f-423b-81b0-de98570413e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input is -  ['love', 'it'] when\n",
            "Input is -  ['love', 'to'] see\n",
            "Input is -  ['love', 'the'] way\n"
          ]
        }
      ],
      "source": [
        "rnn_word_pred(['love', 'it'])\n",
        "rnn_word_pred(['love', 'to'])\n",
        "rnn_word_pred(['love', 'the'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "RNN Example 2.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}